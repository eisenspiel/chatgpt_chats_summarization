# ğŸ§  Chat Summarization Project

This project is designed to summarize long personal chats into structured summaries, preserving important details, emotional tone, and topic continuity.

---

## ğŸ“ Project Structure

```
/chat_summarization_project
â”‚â”€â”€ Dockerfile              # ğŸ³ Runs the project in Docker
â”‚â”€â”€ main.py                 # ğŸ§  Core script with all processing logic
â”‚â”€â”€ step_0_normalize.py     # ğŸ”„ Step 0: Normalize raw data
â”‚â”€â”€ step_1_preprocess.py    # ğŸ“ Step 1: Preprocess Messages
â”‚â”€â”€ step_2_segment.py       # ğŸ·ï¸ Step 2: Segment Messages by Topics
â”‚â”€â”€ step_3_extract.py       # ğŸ“Œ Step 3: Extract Key Sentences
â”‚â”€â”€ step_4_emotion.py       # ğŸ­ Step 4: Detect Emotional Tone
â”‚â”€â”€ step_5_summary.py       # ğŸ“„ Step 5: Generate Final Summary
â”‚â”€â”€ input.json              # ğŸ“¥ Raw input data
â”‚â”€â”€ output_step_0.json      # ğŸ“ Output after data normalization
â”‚â”€â”€ output_step_1.json      # ğŸ“ Output after message preprocessing
â”‚â”€â”€ output_step_2.json      # ğŸ“ Topic segmentation result
â”‚â”€â”€ output_step_3.json      # ğŸ“ Extracted key sentences
â”‚â”€â”€ output_step_4.json      # ğŸ“ Emotion detection results
â”‚â”€â”€ output_step_5.txt       # ğŸ“„ Final readable summary
â”‚â”€â”€ README.md               # ğŸ“– Documentation (to be drafted)
```

---

## âœ… Completed Steps

### Step 0: Normalize Raw Data
- Extracts structured messages from complex JSON structure.
- Result: flat list of messages per chat.

### Step 1: Preprocess Messages
- Cleans messages and keeps role and text.
- Result: list of `{role, message}` items.

---

### Step 2: Segment Messages by Topics
- Encodes each message with `all-mpnet-base-v2` (768D).
- Compares adjacent vectors with cosine similarity.
- Splits topics when similarity drops below threshold (0.5).
- Post-processing:
  - Merges emoji-only or very short segments into neighbors.
  - Attempts to merge semantically similar 1-message segments (threshold 0.9).
  - However, current post-processing may still struggle with emotionally continuous replies (future improvement needed).
- Output: `topics[]` field, each with its messages.
- Note: `topic` field is left `null` and will be filled in Step 5.

---

### Step 3: Extract Key Sentences
- For each topic block, splits messages into individual sentences.
- Uses sentence embeddings (MPNet) to rank sentences by cosine similarity to average.
- Selects top 1â€“2 central sentences to store as `key_sentences[]` for each topic.
- Output is written to `output_step_3.json`.

---

## ğŸ”œ Future Steps

### Step 4: Detect Emotional Tone
- Analyze the emotional tone of each topic using a sentiment/emotion classifier.
- Assign labels like `joy`, `sadness`, `love`, `curiosity`, etc.
- Store as `emotion` key in each topic block.
- Output to `output_step_4.json`.

### Step 5: Generate Final Summary
- Use GPT or T5 model to generate a final summary based on:
  - `key_sentences`
  - `emotions`
  - `topic flow`
- Each topic receives a short paragraph summary and optional topic name.
- Final summary saved to `output_step_5.txt`.

---

## ğŸ“Œ Known Issues / Future Improvements

- Multi-topic messages are not yet split; each message is treated as a unit.
- Emotional or dialog-based continuity is not yet fully captured in topic segmentation.
- Segment merging logic may miss emotionally tied short messages even with relaxed thresholds.
- Consider emotion-based merge logic or conversation-flow heuristics in future.

---